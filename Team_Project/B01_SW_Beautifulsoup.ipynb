{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Beautifulsoup.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOdlcrV0QIKSH4Fdb1fVHoT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RbXi7YCtYsl","executionInfo":{"status":"ok","timestamp":1618289283311,"user_tz":-540,"elapsed":5802,"user":{"displayName":"이승우","photoUrl":"","userId":"16651682666631750301"}},"outputId":"23695e28-84c5-47b8-e4c7-a25e652e3c10"},"source":["pip install requests "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVk__iiZuC6j","executionInfo":{"status":"ok","timestamp":1618289286309,"user_tz":-540,"elapsed":8767,"user":{"displayName":"이승우","photoUrl":"","userId":"16651682666631750301"}},"outputId":"9fc64d16-8e1c-4592-ff35-32cbfb04ac77"},"source":["pip install bs4"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fiz5jRb-t2lJ"},"source":["import requests\n","from bs4 import BeautifulSoup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bqo9J6Ez1a9O"},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bf1t3qoHuFuQ"},"source":["# 삼성전자 검색\n","url = 'https://finance.naver.com/item/news_news.nhn?code=122870&page='"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yFFNJksZws4E"},"source":["# page_num for문 돌릴때 쓸거\n","page_num=1\n","res = requests.get(url+f'{page_num}')\n","html = res.text\n","soup = BeautifulSoup(html, 'html.parser')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOxOmAgKxHPs"},"source":["title_selector = 'body > div > table.type5 > tbody > tr > td.title > a'  #> title, 본문url selector\n","time_selector = 'body > div > table.type5 > tbody > tr > td.date'   #> datetime selector\n","content_selector = 'div#news_read'  #> 본문 내용 selector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xB5JYqwdyEZN"},"source":["titles = soup.select(title_selector)\n","times = soup.select(time_selector)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jn0DjpshyF3F"},"source":["data_titles = []\n","data_address = []\n","data_times = []\n","\n","for title in titles:    #> 본문 url, title 을 각자의 배열에 append\n","    data_titles.append(title.text)\n","    data_address.append('https://finance.naver.com/'+title.get('href'))\n","for time in times:  #> datetime 을 배열에 apeend\n","    data_times.append(time.text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ex3MvZvWyGPQ"},"source":["data = {}   #> data에 dict에 배열 삽입\n","data['title'] = data_titles\n","data['time'] = data_times\n","data['address'] = data_address"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lVhrEfd54PFr"},"source":["data_contents = []\n","#> 본문내용을 위 data dict에서 불러와서 그 주소로 다시 접속\n","for url in data['address']:\n","    res = requests.get(url)\n","    html = res.text\n","    soup = BeautifulSoup(html, 'html.parser')\n","    contents = soup.select(content_selector)\n","    for content in contents:\n","        data_contents.append(content.text.split(sep='@')[0]) #> 기자 이름 뒤에 @이메일주소 전의 내용만 삽입"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJB5llk939kM"},"source":["data['content'] = data_contents #> data dict에 본문 내용 추가"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"du9xlbxXMb_8"},"source":["test = pd.DataFrame(data) #> dataframe 형식으로 바꾸기"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaeBCly_MCWS"},"source":["test.to_csv('test.csv', sep=',', na_rep='NaN') #> dataframe을 csv파일로 저장"],"execution_count":null,"outputs":[]}]}